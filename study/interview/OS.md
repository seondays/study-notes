## 1. 시스템 콜이 무엇인지 설명해 주세요.
시스템 콜은 애플리케이션이 운영체제가 제공하는 서비스를 사용하기 위해서 커널에게 요청하는 인터페이스입니다. 

시스템 콜은 다양한 운영체제 기능에 접근할 수 있는 인터페이스를 제공하며, 이를 이용하여 파일 입출력, 메모리 관리, 프로세스 관리 등 다양한 작업을 수행할 수 있게 합니다.

#### 💫 운영체제의 커널이란 무엇인가요?
운영체제의 커널이란 운영 체제의 핵심 구성 요소로, 하드웨어와 프로세스 간의 인터페이스 역할을 합니다.

### 1-1. 우리가 사용하는 시스템 콜의 예시를 들어주세요.
우리가 일반적으로 사용하는 시스템 콜에는 파일과 관련된 open, read, write, 통신과 관련된 socket, bind, listen 등이 있습니다.

kill , 권한 변경

### 1-2. 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
프로그램이 시스템 콜을 호출하면, 시스템 콜의 호출을 위해 트랩이 발생하여 사용자 모드에서 커널 모드로 전환됩니다. 이후 호출된 시스템 콜을 식별하여 이에 해당되는 작업이 실행됩니다. 작업 처리 완료 이후 다시 커널 모드에서 사용자 모드로 전환되고, 함수의 반환 결과를 받아 계속해서 프로그램이 진행됩니다. 

### 1-3. 시스템 콜의 유형에 대해 설명해 주세요.
프로세스 제어 → 프로세스 관리와 관련된 시스템 콜
파일 관리 → 파일 조작과 관련된 시스템 콜
메모리 관리 → 메모리 할당과 해제, 가상 메모리 등과 관련된 시스템 콜
장치 관리 → 장치 제어 작업과 관련된 시스템 콜
보안 → 권한이나 사용자 관련 시스템 콜
네트워크 → 소켓 생성과 연결 등 네트워크 관련 시스템 콜

### 1-4. 운영체제의 Dual Mode 에 대해 설명해 주세요.
운영체제에서 시스템의 보호와 안정성을 위해 동작 모드를 사용자 모드와 커널 모드로 구분하는 것입니다.

사용자 모드는 일반적인 사용자 프로그램이 실행되는 모드로, 사용자 모드에서는 직접적으로 하드웨어 자원에 접근하는 것이 제한됩니다.

커널 모드는 운영체제의 핵심 부분이 실행되는 모드로, 커널 모드에서는 하드웨어 자원에 대한 직접 접근이 가능해집니다.

필요한 경우 사용자 모드에서 시스템 콜을 이용하여 커널 모드에 하드웨어 자원 접근을 요청할 수 있습니다.

### 1-5. 왜 유저모드와 커널모드를 구분해야 하나요?
가장 중요한 이유는 사용자 프로그램이 직접적으로 시스템의 핵심 부분에 접근하여 각종 문제를 발생시키는 것을 방지하기 위한 시스템 보호 목적입니다. 듀얼모드를 통해 중요한 운영체제 커널의 데이터를 손상시키는 것을 방지하고, 각 프로세스들이 자신의 메모리 구역을 벗어나 다른 메모리 구역에 영향을 미치지 않도록 할 수 있습니다.

### 1-6. 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
각 시스템 콜 별로 고유한 식별자인 번호가 존재합니다. 운영체제는 이 식별 정보를 미리 테이블에 정의해두고, 이를 확인하여 시스템 콜을 구분합니다.

## 2. 인터럽트가 무엇인지 설명해 주세요.
인터럽트란 CPU가 프로그램을 실행하고 있을 때, 다른 하드웨어나 소프트웨어 등에서 발생하는 예외적인 상황에 대한 알림 신호입니다.

### 2-1. 인터럽트는 어떻게 처리하나요?
CPU는 매 사이클마다 인터럽트 체크를 통해 인터럽트가 발생했는지 확인합니다. 만일 인터럽트가 발생했다면 CPU는 현재 작업을 중단하고 현재까지의 작업 상태를 저장합니다. CPU는 발생 인터럽트를 처리할 루틴이 있는 주소로 이동해 이를 처리한 후, 중단했던 작업으로 돌아가거나 혹은 다른 작업을 시작할 수도 있습니다.

### Polling 방식에 대해 설명해 주세요.
폴링 방식은 CPU가 주기적으로 장치의 상태를 확인하는 방식입니다. 장치가 신호를 먼저 보내는 인터럽트 방식과 반대되는 방식으로, 계속해서 장치의 상태를 기다리면서 확인해야 하기 때문에 CPU 자원의 낭비가 발생합니다.

### HW / SW 인터럽트에 대해 설명해 주세요.
하드웨어 인터럽트는 디스크 O/I나, 키보드 입력 등등 외부의 하드웨어 장치로부터 보내지는 인터럽트를 의미합니다.

반면 소프트웨어 인터럽트는 트랩이라고도 불리며 소프트웨어에서 발생하는 예외 상황이나 시스템 콜에 의해 발생하는 인터럽트를 의미합니다.

### 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
다중 인터럽트가 발생하는 경우, 우선 순위가 높은 인터럽트를 먼저 처리하게 됩니다.

일반적으로 하드웨어 인터럽트가 소프트웨어 인터럽트보다 우선 순위가 높습니다. 전원 이상이나 CPU의 하드웨어 오류 같은 경우는 우선순위가 높지만, 프로그램에서 발생하는 예외 트랩은 우선순위가 낮습니다.

인터럽트의 우선순위를 판별하는 방법에는 하드웨어적인 방법과 소프트웨어적인 방법이 있습니다.

## 3. 프로세스가 무엇인가요?
프로세스란 실행 중인 프로그램을 의미합니다.

### 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
프로그램은 코드로 저장되어 있는 아직 실행되지 않은 상태를 의미하고, 프로세스는 프로그램이 CPU에 의해 실행되고 있는 것을 의미하며, 스레드는 프로세스 안에서의 실행 흐름을 의미합니다.

### PCB가 무엇인가요?
Process Control Block으로, 프로세스를 제어하기 위해 프로세스의 정보들을 보관하는 곳입니다.

PID, 프로세스 상태, PC, CPU의 레지스터 상태값을 저장하기 위한 공간, 가상 메모리 사용시 참고할 메모리 관리 정보, 프로세스 우선순의 정보 등등의 값이 저장되어 있습니다.

### 그렇다면, 스레드는 PCB를 갖고 있을까요?
아니오 스레드는 PCB가 없습니다. 스레드는 프로세스 내부에서 여러 실행 흐름을 실행하기 위한 개념으로, 실행을 위한 최소한의 정보인 스택과 PC, 스레드의 상태정보를 제외한 다른 것들은 프로세스의 값을 참고하기 때문입니다. 

### 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
리눅스에서 프로세스가 생성될 때에는 fork 시스템 콜이 사용됩니다. fork를 통해 이를 호출한 부모 프로세스와 동일한 자식 프로세스가 생성되며, 자식 프로세스는 이후 exec 시스템 콜을 통해 요청받은 프로그램으로 대체합니다.

### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
자식 프로세스가 상태를 알리지 않고 죽게 되는 경우에는 PID와 상태 정보가 프로세스 테이블에 남아 있게 되며, 이는 좀비 프로세스라고 불립니다. 부모 프로세스가 wait 계열 시스템 콜을 호출해서 자식 프로세스의 종료 상태를 확인해야 좀비 프로세스가 사라지게 됩니다.

부모 프로세스가 먼저 죽는 경우, 자식 프로세스가 남았다면 이는 고아 프로세스가 되며 systemd이 고아 프로세스의 부모 프로세스가 됩니다. 역시 systemd가 주기적으로 wait 시스템 콜을 통해 고아 프로세스들을 처리합니다.

### 리눅스에서, 데몬프로세스에 대해 설명해 주세요.
데몬프로세스란 일반적으로 사용자와 직접 상호작용하지 않으며, 특정 기능의 처리를 위해 백그라운드에서 계속해서 실행되고 있는 프로세스입니다. 

데몬프로세스는 프로세스 이름 끝에 d가 들어가는 것이 일반적이며, 대표적인 데몬프로세스로 httpd, named 등이 있습니다.

### 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
리눅스 프로세스 트리의 루트 노드에 위치하는 프로세스는 PID 1인 프로세스로 init 또는 systemd라고 불립니다.

첫 번째로 생성되는 프로세스로, 각종 시스템을 초기화하며 모든 다른 프로세스들은 이 프로세스의 자손이 됩니다. 또 1번 프로세스는 고아 프로세스들을 입양하고 이들을 처리하는 역할도 수행합니다.

만일 이 프로세스가 종료되는 경우에는 전체 시스템이 셧다운됩니다.

## 4. 프로세스 주소공간에 대해 설명해 주세요.
프로세스 주소 공간이란 운영체제가 각 프로세스에게 할당하는 독립적인 가상 메모리 공간입니다. 모든 프로세스는 자신만의 고유한 주소공간을 가지며 이는 코드 영역, 데이터 영역, 힙, 스택 등의 여러 논리적 영역으로 분할되어 있습니다.

### 4-1. 초기화 하지 않은 변수들은 어디에 저장될까요?
초기화 하지 않은 전역, 정적 변수들은 초기화하지 않은 데이터 영역 BSS에 저장됩니다. BSS의 변수들은 프로그램이 시작될 때 기본값 0으로 자동 초기화됩니다.

BSS를 통해 초기화되지 않은 변수들의 값을 따로 저장하지 않고 실행시점에 초기화함으로써 메모리 효율성에 도움을 줄 수 있습니다.

### 4-2. 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
실제로 스택과 힙의 크기는 메모리에서 매우 큰 값은 아닙니다.

스택 크기는 생성 시점에 운영체제 설정에 따라 정해진 크기대로 결정되며, 이 크기를 넘어가게 되면 스택오버플로우 문제가 발생합니다. 반면 힙은 동적으로 할당된 메모리를 관리하는 영역이기 때문에, 프로그램의 요청에 따라 유동적인 크기를 가지게 됩니다. 하지만 여전히 설정된 최대치가 존재합니다.

### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
스택이 힙보다 접근 속도가 더 빠릅니다.

 스택에 접근할 때 스택 프레임의 주소에 단순 계산으로 오프셋을 더하는 것 만으로 빠르게 접근할 수 있기 때문입니다. 또한 실제로 메모리 위에 값들이 연속적으로 배치되어 있기 때문에 캐시 히트가 높아 CPU 캐시 효율이 더 좋습니다.

반면 힙은 메모리 할당과 해제의 반복으로 인해 메모리 내에서 필요 객체들이 흩어져 있을 확률이 높아 상대적으로 스택보다 캐시 효율이 좋지 않으며, 힙에 접근하기 위해서는 간접 참조가 필요하기 때문에 스택보다 접근 속도가 느립니다.

### 다음과 같이 프로세스의 주소 공간을 분할하는 이유가 있을까요?
용도별로 주소 공간을 분할하여 각 공간마다 용도에 맞게 효율적이고 최적화된 메모리 관리 방식을 적용하기 위해서입니다.

예를 들면 분할한 각각에 메모리에 대해 읽기 쓰기 실행 과 같은 접근 권한을 다르게 적용할 수 있고, 메모리 영역 특성별로 할당과 해제 등을 독립적으로 설정할 수 있는 등의 이점이 있습니다.

### 스레드의 주소공간은 어떻게 구성되어 있을까요?
스레드의 주소공간은 스택과 PC 값을 포함하는 레지스터의 값으로 구성되어 있습니다.

### "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.
자료구조 스택과 메모리의 스택 영역은 동작 원리에서 연관이 있습니다. 스택 영역에는 함수의 호출 순서대로 스택 프레임의 형태로 쌓이고 반환 순서대로 해제되는데, 이 순서가 자료구조 스택처럼 후입선출과 동일하게 진행되기 때문입니다.

반면 이진 트리 형태의 자료구조 힙과 동적 메모리 할당을 위한 메모리의 힙 영역은 따로 연관있는 개념이 아닙니다. 

### IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
프로세스 간에 데이터를 주고받기 위한 기법 중 하나인 공유메모리는 힙이나 스택과는 상관 없이 별도의 주소공간에 들어가게 됩니다.

### 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
스택 영역은 프로세스 시작 시 정해진 설정에 따라 크기가 결정되며, 힙 영역은 메모리 할당 요청에 따라 가변젹으로 조절됩니다.

사용자는 시스템 설정의 조절을 통해 스택 크기를 조절할 수 있고, JVM 사용 시에는 실행 옵션을 통해 힙 영역도 제한을 두는 방식으로 크기를 조절할 수 있습니다.

## 5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.
장기 스케줄러는 작업 큐에 들어가 있는 프로세스를 선택하여 준비 상태로 전이한 이후, 준비 큐에 전달하는 역할을 합니다. 

중기 스케줄러는 메모리에 적재된 프로세스의 수를 관리하고 조절하는 역할을 합니다. 너무 많은 프로세스가 메모리에 올라와 있는 경우 프로세스를 메모리에서 디스크로 보내고, 메모리에 여유가 생기면 다시 적재하는 작업을 진행합니다.

단기 스케줄러는 준비 큐의 프로세스를 디스패칭하여 실행시키기 위한 것을 스케줄링합니다. 

### 5-1. 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
현대 OS에서는 단기 스케줄러는 필수적으로 존재하지만, 장기와 중기 스케줄러는 별도로 사용하는 일이 드뭅니다.
프로그램을 생성하면 즉시 프로세스가 생성되는 경우가 많으므로, 장기 스케줄러를 별도로 사용하는 일은 드물고, 중기 스케줄러의 역할인 프로세스 스와핑을 이용한 메모리 관리도 현대 OS에서는 메모리 관리자가 담당하는 경우가 많습니다.

### 5-2. 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
프로세스는 생명주기 동안 일반적으로 생성-준비-실행-대기-종료의 상태를 거칩니다.

생성 단계는 작업이 시스템에 제출되고 운영체제가 PCB를 생성하고 PID가 결정되는 단계이며, 이 단계의 프로세스는 작업 큐로 들어갑니다.

준비 단계는 프로세스가 실행을 위한 준비를 마쳤으며, CPU 할당을 기다리는 상태입니다. 준비 큐에 머물고 있다가 스케줄러에 의해 디스패치가 되면 실행 상태가 됩니다.

실행 상태는 프로세스가 CPU에 의해 실행 처리되고 있는 상태입니다.

대기 상태는 실행 상태에서 이벤트가 발생하여 이 이벤트의 완료를 위해 잠시 대기하고 있는 실행 보류중인 상태입니다. 실행중인 프로세스가 IO 작업을 하거나 페이지 교환 작업을 할 때 다른 프로세스들에 CPU를 할당하여 CPU를 효율적으로 사용하기 위한 장치입니다.

종료상태는 실행상태의 프로세스가 모든 처리를 완료하거나, 여러 이상 발생으로 프로세스를 강제로 종료시키거나 하여 종료된 상태입니다.

### 5-3. preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
선점 환경에서는 실행 상태를 준비 상태로 변경할 수 있기 때문에 모든 상태가 가능하지만, 비선점 환경에서는 실행 상태를 강제로 준비 상태로 변경할 수 없기 때문에 실행에서 준비 상태로의 전이는 존재하지 않습니다.

### 5-4. Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
메모리가 부족할 경우 실행 상태인 프로세스를 디스크로 보내는 작업을 통해 suspended 상태로 전이하거나, 최악으로는 종료 상태가 될 수 있습니다. 

현대 OS에서는 전체 프로세스를 디스크로 스왑아웃 하기보다는 페이지 교체를 통해 메모리를 관리하여 계속 프로세스가 실행될 수 있도록 하는 방법을 사용하고 있습니다.

-----
## 6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
컨텍스트 스위칭 시에는 기존 실행중이던 프로세스의 스택 포인터와 프로그램 카운터의 내용을 저장해두고, 해당 프로세스의 상태를 다시 준비나 대기로 전이합니다. 다음으로 새로 실행할 프로세스의 PBC 내용들을 가져와서 CPU레지스터에 올린 후 실행시킵니다.

### 6-1. 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
하나의 프로세스에 속해 있는 스레드들은 같은 메모리 영역을 공유하고 있기 때문에, 컨텍스트 스위칭 시 현재 CPU 레지스터의 값을 변경해주는 작업만으로 가능하지만, 프로세스간의 컨텍스트 스위칭은 이 기본적인 작업에 추가적으로 가상 메모리 주소 관련 처리가 필요합니다.

기존 프로세스의 메모리 주소 체계에서 새로운 메모리 주소 체계로 변경해줘야 하고, 가상 메모리 정보를 물리 메모리 정보와 매핑하는 정보가 저장된 캐시 또한 비워져야 하는 작업이 수행되어야 합니다.

### 6-2. 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
기존 프로세스 정보는 프로세스의 PCB로 저장됩니다. PCB에는 레지스터 값, PID, 프로세스 상태 등이 포함되어 있습니다.

### 6-3. 컨텍스트 스위칭은 언제 일어날까요?
- 주어진 타임 슬라이스를 모두 사용하는 경우
- 인터럽트가 발생하는 경우
- 더 우선순위가 높은 작업이 들어오는 경우

## 7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
- FCFS (First-Come First-Served)
	- 준비 큐에 먼저 들어온 프로세스가 먼저 실행되는 비선점 방식의 알고리즘
- Priority
	- 프로세스의 우선 순위를 매겨서 우선 순위가 높은 프로세스를 실행시키는 알고리즘
- JSF (Shortest Job First)
	- 준비 큐의 프로세스 중, 실행시간이 가장 짧다고 예상되는 프로세스를 먼저 실행하는 비선점 방식의 알고리즘
- SRT (Shortest Remaining Time)
	- SJF 알고리즘의 선점 방식. 준비 큐에서 기다리는 프로세스 중 남은 실행시간이 가장 짧다고 예상되는 것을 먼저 디스패치
- RR (Round Robin)
	- 준비 큐에 도착한 순서대로 프로세스를 실행하지만, 정해진 타임 슬라이스 내에 작업을 끝내지 않으면 중단시키고 다시 준비 상태로 전이되는 선점 방식의 알고리즘
- HRN (Highest Responce Ratio Nest)
	- 준비 큐에서 기다리는 프로세스 중에서 응답 비율이 가장 큰 것을 먼저 디스패치하는 비선점 방식의 알고리즘
	- 즉, 예상실행시간이 짧을수록, 대기시간이 길수록 응답 비율이 커진다.
	- 예상실행시간이 모두 다른 프로세스가 동시에 들어오는 경우 → 예상실행시간이 가장 짧은 프로세스를 선택
	- 예상실행시간이 모두 동일한 프로세스가 다른 시간에 들어오는 경우 → 대기시간이 가장 긴 프로세스를 선택
- 다단계 피드백 큐 스케줄링
	- 입출력 중심인 프로세스와 연산 중심인 프로세스의 특성에 따라 서로 다른 시간 할당량을 부여하는 선점 방식의 스케줄링 알고리즘
	- 여러 단계의 큐로 나누어져 있으며, 각 큐는 다음 단계에 큐에 피드백을 준다. 단계가 커질수록 시간 할당량은 늘어나도록 되어 있음

### 7-1. RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
타임 슬라이스 값을 너무 짧게 설정한다면 빈번한 컨텍스트 스위칭이 일어나 이에 대한 오버헤드가 발생할 수 있고, 반면 타임 슬라이스 값을 너무 길게 설정한다면 하나의 프로세스의 시간이 다할 때까지 대기중인 프로세스들이 오래 기다려야 하는 문제가 발생할 수 있습니다.

### 7-2. 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
RR 알고리즘을 사용하는 것이 적합한 방법 중 하나라고 생각합니다. 정해진 타임 슬라이스만큼 프로세스들이 번갈아 실행되기 때문에, 마치 동시에 실행하는 것처럼 작동하여 다른 프로세스들이 실행되면서도 상시 프로세스 역시 계속해서 실행될 수 있기 때문입니다.

### 7-3. 동시성과 병렬성의 차이에 대해 설명해 주세요.
- 동시성은 여러 작업이 마치 동시에 사용되도록 하는 기법
- 병렬성은 실제로 여러 CPU나 코어를 사용하여 여러 작업을 동시에 실행하는 것

### 7-4. 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
- IO 작업과 CPU 작업 프로세스 작업을 균형적으로 해결하기 어려웠던 문제점을 해결해줌
	- 짧은 작업 시간을 가지는 IO 작업 프로세스는 자연스럽게 낮은 레벨의 큐에서 작동되고, CPU 작업 프로세스는 오래 실행되지만 높은 레벨의 큐에서 작동하기 때문에 균형을 잡을 수 있게 됨
- 특정 프로세스가 계속 조건에서 밀려나 기아 현상이 발생하는 문제점을 해결해줌
	- 특정 레벨에서 작업을 이미 진행한 프로세스는 낮은 우선권을 가지는 높은 레벨 큐로 이동되므로, 계속 실행되지 못하는 프로세스가 먼저 실행될 가능성이 높아짐

### 7-5. FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?

### 7-6. 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?

### 7-7. 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?

## 8. 뮤텍스와 세마포어의 차이점은 무엇인가요?
뮤텍스와 세마포어의 차이점은 자원에 대해 접근할 수 있는 스레드의 수에 차이가 있습니다. 

- 뮤텍스 : 오직 하나의 스레드만이 자원에 접근하도록 보장하는 방식. 락을 획득한 스레드만이 임계영역을 나가면서 락을 해제할 수 있다.
- 세마포어 : 자원에 동시 접근할 수 있는 수를 설정하여 사용하는 방식. 락을 걸지 않은 스레드도 락을 해제할 수 있다. 세마포어를 1로 설정해서 뮤텍스처럼 활용도 가능

#### 💫 뮤텍스와 세마포어란?
임계 영역에서의 동시성 문제를 해결하기 위해 공유자원에 대한 접근 동기화를 제한하는 기술

### 8-1. 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
이진 세마포어는 세마포어 카운트를 0 혹은 1만 가질 수 있도록 하여 뮤텍스처럼 사용하고자 하는 방식이지만, 여전히 외부 스레드도 락을 해제할 수 있다는 것에 차이점이 있습니다.

#### 💫 어차피 하나의 스레드만이 세마포어를 획득할 수 있을텐데 외부에서 해제하는 것이 의미가 있을까?

### 8-2. Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
- 락 해제만을 기다리고 있는 상황이기에 락의 획득이 빠르게 이루어진다는 장점
- CPU가 계속해서 루프 작업을 해야 하기 때문에 자원의 낭비 현상이 발생한다는 단점
	- 루프 횟수에 제한을 두고, 계속해서 락을 획득하지 못한다면 CPU 자원 반납
	- 시도 초반에는 빠른 속도로 확인, 대기 시간이 길어질수록 확인 텀 늘리기

#### 💫 스핀락이란?
레이스 컨디션 상황에서 락이 반환될 때까지 계속해서 루프를 돌며 재시도하도록 구현된 락

### 8-3. 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?
- 커널의 제어 아래에서 락 획득과 해제가 이루어지므로, 안정적이고 신뢰성이 보장
- 시스템 콜 호출 작업을 위한 모드 전환에서 오버헤드 발생
	- 락을 사용하지 않고 원자적 연산과 재시도 기법으로 동시성을 보장하는 알고리즘을 사용
	- 임계영역이 짧은 경우 스핀락 사용하여 커널 진입하지 않고 처리하도록 시도 가능

### 9. Deadlock 에 대해 설명해 주세요.
데드락은 두 개 이상의 작업이 서로에게 필요한 자원을 점유한 상태에서 상대방을 기다리는 상황이 되어 결과적으로 아무런 작업도 정상적으로 완료되지 못하는 현상을 의미합니다.

### 9-1. Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
- 상호 배제 : 자원은 한 번에 하나의 프로세스만 사용 가능한 것
- 비선점 : 먼저 선점되어 점유하고 있는 자원을 뺏을 수 없는 것
- 점유와 대기 : 프로세스가 자원을 점유하고 있는 상태에서 다른 자원을 기다리는 상태
- 환형 대기 : 프로세스들이 원형 상태로 자원을 대기하고 있는 상태

### 9-2. 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
만일 4가지 모두 충족되는 것이 아니라 그 이하의 조건만 발생하는 경우에는 데드락을 회피할 방법이 존재하게 되기 때문입니다.
- 상호 배제가 없는 경우 → 자원을 공유해서 사용 가능하기 때문에 데드락이 발생하지 않음
- 선점 방식인 경우 → 한 쪽이 자원을 뺏어서 사용할 수 있기 때문에 데드락이 발생하지 않음
- 점유와 대기가 아닌 경우 → 자원을 점유하면서 동시에 대기하지 않는다면, 데드락이 발생하지 않음
- 환형 대기가 아닌 경우 → 자원 대기가 한방향이라면, 무한 순환이 생기지 않아 데드락이 발생하지 않음

### 9-3. 어떤 방식으로 예방할 수 있을까요?
간단하게 데드락이 발생하기 위한 4가지 조건이 모두 발생하는 일이 없도록 처리하면 됩니다.

- 점유와 대기 조건 발생을 예방하기 위해, 프로세스가 처음에 필요한 모든 자원을 요청하게 하는 방법을 사용할 수 있습니다.
- 환형 대기 조건 발생을 예방하기 위해, 자원에 순서를 부여해서 프로세스가 자원을 요청할 때 오름차순 방향으로만 요청할 수 있도록 하는 방법을 사용할 수 있습니다.

### 9-4. 왜 현대 OS는 Deadlock을 처리하지 않을까요?
드물게 발생하는 데드락의 처리를 위해 OS 시스템 전반에서 발생하는 모든 데드락을 감지, 회피, 예방하는 방식을 사용하는 것은 리소스 사용의 효율이 낮은 작업이기 때문입니다.

따라서 특별히 데드락을 처리하지 않고 무시하는 전략을 채택합니다.

### 9-5. Wait Free와 Lock Free를 비교해 주세요.
락 없이도 최소 하나의 스레드는 작업을 완료할 수 있다.
모든 스레드가 시간 내에 작업을 완료할 수 있다.

둘 다 락을 사용하지 않으며 원자적 연산을 사용한다.

### 10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.

### 10-2. 링커와, 로더의 차이에 대해 설명해 주세요.
링커는 컴파일 시 라이브러리나 함수의 사용을 위해 목적 파일들을 연결하여 실행 파일을 만들어주는 역할을 하고, 로더는 실제 프로그램의 실행을 위해 메모리에 로드하는 과정을 담당합니다.

### 10-3. 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
컴파일 언어는 전체 소스코드를 컴파일러를 통해 기계어로 번역하고 이를 실행하는 반면, 인터프리터 언어는 소스코드를 한 줄씩 실행하는 방식입니다.

### 10-4. JIT에 대해 설명해 주세요.
JIT 방식은 

### 10-5. 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
자바는 소스코드를 바이트코드로 바꾼 후, 이를 JVM에서 한 줄씩 실행하는 방식입니다.

- Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
- 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?

### 11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
ICP는 실행 중인 프로세스 간에 데이터를 공유하기 위한 매커니즘입니다.
- 파이프 방식
- 메시지 큐
- 공유 메모리

### 11-1. Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
공유 메모리는 프로세스들 사이에서 값을 공유하기 위해 사용하는 메모리 부분입니다. 공유 메모리에는 여러 프로세스들이 모두 접근하여 해당 값을 사용할 수 있으므로, 레이스 컨디션이 발생하기 때문에 동기화 부분을 유의해서 사용해야 합니다.

### 11-2. 메시지 큐는 단방향이라고 할 수 있나요?
메시지 큐는 기본적으로 단방향이지만, 두 개를 사용하여 양방향으로도 데이터를 주고받을 수 있습니다.

---
## 12. Thread Safe 하다는 것은 어떤 의미인가요?
어떤 코드가 주어졌을 때  이 코드가 동시에 여러 스레드에서 어떤 순서로 실행되는 경우에도 문제가 발생하지 않고 올바른 결과가 나온다는 것을 의미합니다.

### 12-1. Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
- 한 시점에 하나의 스레드만 코드에 접근할 수 있도록 하는 상호 배제
	- 락과 같은 잠금 매커니즘 사용
- 대상 코드를 불변으로 처리하여, 여러 곳에서 접근해도 수정 불가능하도록
-  공유 데이터 대신 ThreadLocal와 같은 개념을 이용하여 각 스레드가 자신만의 공간을 사용하도록

### 12-2. Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
피터슨 알고리즘은 상호 배제를 위한 병렬 프로그래밍 알고리즘으로, 두 프로세스가 하나의 자원을 함께 사용할 때 문제가 발생하지 않도록 해주는 장치입니다.

한계점으로는 피터슨 알고리즘은 두 개 이상의 프로세스에 적용하기 위해서는 복잡해진다는 것과 상대를 기다리면서 계속해서 루프를 돌기 때문에 CPU 자원의 낭비가 발생할 수 있다는 점이 있습니다.

### 12-3. Race Condition 이 무엇인가요?
공유 자원에 여러 스레드들이 접근하여 경쟁하며, 이로 인해 결과값에 영향을 줄 수 있는 동기화 문제가 발생하는 상황을 의미합니다.

### 12-4. Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
반드시 락을 사용해야 하는 것은 아닙니다. 실행 단위별로 방해받지 않고 실행되는 원자적인 연산이나, 변경할 수 없는 불변 객체 사용, 스레드 로컬 저장소 등의 방법이 있습니다.

## 13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.
- 스레드 풀 : 작업을 위한 스레드들을 미리 생성해서 모아두고, 필요에 따라 풀 내부의 스레드들을 재사용하는 방식
- 모니터 : 작업이 상호 배제와, 조건 대기를 가질 수 있도록 하는 동기화 메커니즘 (조건이 충족될 때까지 대기하게 함)
- fork join : 큰 작업을 재귀적으로 작은 작업으로 분할하고, 이를 병렬로 처리하여 최종적으로 합쳐서 결과를 만들어내는 방법

### 13-1. Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
일반적으로 리틀의 법칙을 활용하여 응답당 응답시간을 고려하거나, CPU 코어 개수를 기반으로 스레드 풀 크기를 정한다고 알려져 있습니다. 뿐만 아니라 작업의 종류와 성격, 응답 시간도 영향을 끼칩니다.

이러한 점들을 바탕으로 실제 서비스 환경에서 부하테스트를 통해 적절한 스레드의 수를 결정하는 것이 중요하다고 생각합니다.

### 13-2. 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?
- 합병 정렬 : 기존 데이터의 정렬 상태와 상관 없이 거의 일정한 성능을 가지고 있으며 정렬 후에도 같은 값들의 순서가 유지되는 안정 정렬이다. (n log n)
- 퀵 정렬 : 빠르지만 피벗 선택이 잘못되면(최솟값 최댓값) 속도가 느려질 수 있음
- 힙 정렬 : 힙 자료구조 사용하여 정렬. 공간 사용의 효율이 높지만 불안정
- 삽입 정렬 : 거의 정렬되어 있는 데이터인 경우 사용하면 속도가 매우 빠름 (평균은 n^2)

## 14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
메모리 계층성이란 접근 속도와 용량, 비용의 균형을 위해 여러 계층의 메모리 구조를 구성하는 것을 의미합니다.

CPU와 가까운 순서대로 레지스터, 캐시 메모리, 주 메모리(RAM), 보조 저장장치(HDD/SSD) 순으로 구성됩니다. 이 계층 구조는 속도와 용량의 트레이드오프를 최적화하기 위한 것입니다.

그 중 캐시 메모리는 필요한 값을 접근하기 가까운 곳에 보관하여 빠르게 값을 사용하기 위한 역할을 하는 메모리입니다. 

### 캐시 메모리는 어디에 위치해 있나요?
캐시 메모리는 CPU와 주 메모리 사이에 위치합니다.

### L1, L2 캐시에 대해 설명해 주세요.
L1캐시는 CPU 칩 내부에 내장되어 가장 먼저 참조되는 캐시 메모리입니다. L2캐시는 1L캐시보다는 조금 더 크고 살짝 느린 캐시입니다. 코어별로 존재할 수도 있고, 코어끼리 공유할 수도 있는 캐시입니다. 1L캐시에서 미스가 난 경우 그 다음으로 참조되는 캐시 메모리입니다.

### 캐시에 올라오는 데이터는 어떻게 관리되나요?
캐시에는 자주 접근하는 데이터를 저장하는 것이 핵심이기 때문에 여러 메모리 관리 정책이 존재합니다.

- LRU(Least Recently Used) : 가장 오랫동안 사용되지 않은 데이터를 교체
- LFU(Least Frequently Used) : 가장 자주 사용되지 않는 데이터를 교체
- FIFO (First-In, First-Out) : 가장 먼저 들어온 데이터를 교체
- 무작위로 제거

### 캐시간의 동기화는 어떻게 이루어지나요?
캐시간의 동기화를 위한 여러 프로토콜이 존재합니다.

- MESI :  별도의 플래그(flag)를 할당한 후 플래그의 상태를 통해 데이터의 유효성 여부를 판단
	- Modified(수정) 상태 : 데이터가 수정된 상태
	- Exclusive(배타) 상태 : 유일한 복사본이며, 주기억장치의 내용과 동일한 상태
	- Shared(공유) 상태 : 데이터가 두 개 이상의 프로세서 캐시에 적재되어 있는 상태
	- Invalid(무효) 상태 : 데이터가 다른 프로세스에 의해 수정되어 무효화된 상태
- 스누핑 : 주소 버스를 항상 감시하여 캐시 상의 메모리에 대한 접근이 있는지를 감시하는 구조이다. 다른 캐시에서 쓰기가 발생하면 캐시 컨트롤러에 의해서 자신의 캐시 위에 있는 복사본을 무효화시킨다.
- 디렉토리 : 캐시 블록의 공유 상태, 노드 등을 기록하는 저장 공간인 디렉터리를 이용하여 관리하는 구조이다.

### 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
- 직접 매핑 : 메인 메모리와 캐시를 일정한 크기의 블록으로 나누고, 정해진 위치에 매핑
- 연관 매핑 : 캐시 메모리의 빈 공간 아무 곳에나 저장
- 집합 연관 매핑 : 직접 매핑과 연관 매핑의 하이브리드 방식, 미리 정해진 구역의 빈 공간 아무 곳에나 저장

### 캐시의 지역성에 대해 설명해 주세요.
- 공간 지역성 : 참조된 데이터와 인접한 데이터가 참조될 확률이 높다
- 시간 지역성 : 최근에 참조된 데이터는 다시 참조될 확률이 높다

### 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
이차원 배열의 행은 메모리에 연속적으로 배치되어 있기 때문에, 가로로 탐색하는 경우 캐시의 지역성을 활용할 수 있습니다.
 - 첫 원소 조회에는 캐시 미스가 일어나지만, 그 뒤로는 캐시 라인에 이미 로드된 값을 읽어옴
세로로 탐색하는 열 단위 접근은 메모리 주소가 행의 크기만큼 떨어져 있기 때문에, 캐시의 공간 지역성을 사용하기 어렵습니다.

### 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)
캐시는 캐시 라인이라는 단위로 저장되고 관리됩니다. 따라서 어떠한 데이터에 접근해야 할 때, 캐시는 해당 데이터만 가져오는 것이 아니라 데이터가 속해 있는 일정 단위의 크기 전체를 캐시로 가져옵니다.

이를 통해 캐시의 공간 지역성을 활용할 수 있는 것입니다.

## 15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
프로세스에게 메모리를 할당할 때, 사용 가능한 비어 있는 메모리 공간 중에서 어떤 공간을 줄 것인지 결정하는 다양한 전략이 있으며 그중 대표적인 세 가지 연속 할당 방식은 다음과 같습니다.

- first-fit(최초 적합)
	- 사용 가능한 빈 메모리 공간 중에서, 첫 번째로 마주치는 요청된 메모리 공간을 올릴 수 있는 크기의 공간에 할당
	- 빠르고 구현 간단
	- 할당하고 남은 공간들은 다시 free list에 추가되기 때문에 외부 단편화 유발 가능성이 높음
- best-fit(최적 적합)
	- 사용 가능한 빈 메모리 공간 중에서, 요청된 메모리 크기에 가장 근접한 공간에 할당
	- 메모리 공간을 효율적으로 사용하여 외부 단편화를 최소화
	- 빈 메모리 공간을 찾기 위해 전체를 순회해야 하므로, 할당하는데 시간이 많이 소요
- worst-fit(최악 적합)
	- 사용 가능한 빈 메모리 공간 중에서, 가장 큰 공간을 찾아 할당
	- 할당 후 남는 공간이 비교적 큰 공간이 되어, 다시 그곳에 메모리 할당이 가능할 확률이 높음
	-  빈 메모리 공간을 찾기 위해 전체를 순회해야 하므로, 할당하는데 시간이 많이 소요
	- 가장 큰 공간이 계속 쪼개지기 때문에, 작은 요청들이 많이 들어왔을 때 큰 공간이 빠르게 조각날 수 있으며 오히려 큰 공간이 필요한 미래의 요청을 처리하기 어려울 수 있다.

### worst-fit 은 언제 사용할 수 있을까요?
- 큰 메모리 사용 요청이 빈번할 때 적합

### 성능이 가장 좋은 알고리즘은 무엇일까요?
속도 면에서는 최초 적합이 가장 빠르고, 외부 단편화를 최소화시킨다는 관점에서는 최적 적합이 가장 좋다고 평가받습니다.

## 16. Thrashing 이란 무엇인가요?
스레싱이란 메모리에 접근할 때 페이지폴트 현상이 자주 발생하여 운영체제가 메모리 페이지를 교체하는데 대부분의 시간을 소모하게 되고, 이로 인해 시스템의 성능이 극도로 저하되는 것을 의미합니다.

### Thrashing 발생 시, 어떻게 완화할 수 있을까요?
- 동시에 너무 많은 프로세스가 실행되는 경우에 thrashing 현상 발생 가능, 따라서 동시에 실행되는 프로세스 수를 조정하기
- 워킹 셋을 저장할 충분한 물리적 메모리가 없는 경우라면, 메모리 증설
- 페이지 교체 알고리즘 개선
- 페이지폴트 발생율에 상하한 제한을 걸기

## 23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
두 가지 작업이 존재할 때, 하나의 작업이 나머지 하나의 작업의 결과에 의존하거나 기다려야 한다면 동기, 그렇지 않으면 비동기

하나의 작업이 존재할 때, 호출 시 제어권을 넘겨 준다면 블로킹, 넘겨주었다가 바로 돌려받아서 자신의 작업을 계속 진행할 수 있다면 논블로킹

### 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
동기이면서 논블로킹이고, 비동기면서 블로킹이 가능할 수는 있으나, 일반적으로는 큰 의미는 없다고 생각합니다.

- 논블로킹이라도 동기 작업이라면, 자신의 작업을 다 끝냈더라도 순서상 상대를 기다려야 하기 때문에 상대를 기다려야 하는 상황이 됨
- 비동기지만 블로킹인 경우는 상대를 기다리지 않아도 되지만, 호출하면 제어권이 넘어가 자신의 작업을 아무것도 하지 못하기 때문에 의미가 없게 됨

### I/O 멀티플렉싱에 대해 설명해 주세요.
I/O 멀티플렉싱은 하나의 프로세스(또는 스레드)가 여러 개의 입/출력 채널(예: 소켓, 파일 디스크립터)을 동시에 모니터링하고, 해당 채널에 입/출력 준비가 되었을 때 알림을 받는 메커니즘입니다.

전통적인 블로킹 IO 모델에서는 프로세스가 해당 작업이 완료될때까지 대기해야 했기 때문에 이 문제를 해결하기 위해 등장했습니다.

### 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?
- 멀티플렉싱 시스템 호출을 통해 결과 통지
- polling
- 알림 통지